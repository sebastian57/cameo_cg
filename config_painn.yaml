# Chemtrain PaiNN Configuration Template
# Same structure as config_template.yaml but with PaiNN as the ML backbone

seed: 193749
debug_priors: false

model_context: "painn_cg_protein_4zohB01"
protein_name: "4zohB01"
model_id: "painn_default"

data:
  path: "data_prep/datasets/4zohB01_320K_kcalmol_1bead_notnorm_aggforce.npz"
  max_frames: 2500

preprocessing:
  buffer_multiplier: 2.0
  park_multiplier: 0.95

model:
  ml_model: "painn"  # Options: "allegro", "mace", "painn"
  use_priors: true

  painn_size: "default"  # Options: "default", "large"

  cutoff: 10.0
  dr_threshold: 1.0

  # PaiNN model configurations
  # Keys map directly to painn_neighborlist_pp kwargs (via PaiNN class)
  painn:  # Default size
    hidden_size: 128            # Hidden dimension (required)
    n_layers: 3                 # Number of interaction blocks (required)
    n_rbf: 20                   # Number of radial basis functions
    num_species: 100            # Embedding vocabulary size
    shared_interactions: false   # Share weights across interaction layers
    shared_filters: false        # Share filter network weights
    eps: 1.0e-8                 # Numerical stability constant
    avg_num_neighbors: 21       # Average neighbors (estimate for CG proteins)

  painn_large:  # Larger model for complex systems
    hidden_size: 256
    n_layers: 5
    n_rbf: 32
    num_species: 100
    shared_interactions: false
    shared_filters: false
    eps: 1.0e-8
    avg_num_neighbors: 21

  # Prior energy parameters (same as Allegro/MACE â€” priors are model-independent)
  priors:
    weights:
      bond: 0.5
      angle: 0.25
      dihedral: 0.25
      repulsive: 1.0

    r0: 3.8375435
    kr: 154.50629422490843

    a: [-0.02086511, -0.36341857, -0.50767196, 0.09906029, 0.8319552, -0.00770968, -0.13320648, -1.14116021, 0.18145372, -0.55828783]
    b: [0.67521775, 0.14797897, -0.12157499, -0.8289584, 0.17162394, 0.48646108, 0.56000923, -0.13905056, -0.896762, -1.20144583]

    theta0: 1.8335507
    k_theta: 8.271271714604836

    epsilon: 1.0
    sigma: 3.0

    k_dih: [0.47037187851535034, 0.9495107825945361]
    gamma_dih: [1.3759673785180062, 1.6211158177819938]

optimizer:
  grad_clip: 2.0

  adabelief:
    lr: 5.0e-2
    peak_lr: 0.01
    end_lr: 5.0e-3
    warmup_epochs: 15
    decay_steps: 2500
    beta1: 0.95
    beta2: 0.999
    eps: 1.0e-8
    grad_clip: 5.0
    weight_decay: 2.0e-5

  yogi:
    lr: 1.0e-3
    peak_lr: 1.0e-3
    end_lr: 5.0e-5
    warmup_epochs: 5
    decay_steps: 50
    beta1: 0.9
    beta2: 0.999
    grad_clip: 4.0
    eps: 1.0e-6
    weight_decay: 5.0e-4

ensemble:
  enabled: false
  n_models: 5
  base_seed: 42
  save_all_models: false

training:
  pretrain_prior: false
  pretrain_prior_min_steps: 10
  pretrain_prior_max_steps: 200
  pretrain_prior_tol_grad: 1.0e-6

  stage1_optimizer: "adabelief"
  stage2_optimizer: "yogi"

  epochs_adabelief: 30
  epochs_yogi: 0

  val_fraction: 0.1
  batch_per_device: 16
  batch_cache: 10

  gammas:
    F: 1.0
    U: 0.0

  checkpoint_freq: 10
  checkpoint_path: "./checkpoints_painn"

  export_path: "./exported_models"
