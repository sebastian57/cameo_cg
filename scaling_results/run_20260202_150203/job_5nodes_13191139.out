============================================================
Scaling Test Worker
============================================================
Job ID:         13191139
Nodes:          5
Start devices:  17
End devices:    20
Config:         /p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/config_scaling_test.yaml
Output dir:     /p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scaling_results/run_20260202_150203
============================================================

============================================================
Starting scaling tests from 17 to 20 devices
============================================================

------------------------------------------------------------
Testing with 17 device(s)...
------------------------------------------------------------
  Nodes needed:     5
  Device pattern:   split:4x4+1
  Running training...
2026-02-02 16:30:38.074840: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 2/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 2: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 2/5] JAX distributed initialized
[Rank 2] Local GPUs: 4, Total GPUs: 17
[Rank 2] Local devices: [CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11)]
[Rank 2] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:30:39.245654: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 0/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 0: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 0/5] JAX distributed initialized
[Rank 0] Local GPUs: 4, Total GPUs: 17
[Rank 0] Local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]
[Rank 0] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:30:41.001648: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 3/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 3: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 3/5] JAX distributed initialized
[Rank 3] Local GPUs: 4, Total GPUs: 17
[Rank 3] Local devices: [CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15)]
[Rank 3] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:30:42.632893: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 1/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 1: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 1/5] JAX distributed initialized
[Rank 1] Local GPUs: 4, Total GPUs: 17
[Rank 1] Local devices: [CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
[Rank 1] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[Model] Using Allegro size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 272 does not divide the number of observations 2250. Trainer will skip 74 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 238 does not divide the number of observations 250. Trainer will skip 12 samples for state validation
  warnings.warn(
[Scaling] Node 4/5: local_device_ids = [0]
[Scaling] Node 4: CUDA_VISIBLE_DEVICES = 0
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 4/5] JAX distributed initialized
[Rank 4] Local GPUs: 1, Total GPUs: 17
[Rank 4] Local devices: [CudaDevice(id=16)]
[Rank 4] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16)]
============================================================
SCALING TEST
============================================================
Devices: 17
Distributed: True
Rank: 4/5
Local devices: 1
Global devices: 17
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 380, in <module>
    main()
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 360, in main
    results = trainer.train_full_pipeline()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/training/trainer.py", line 618, in train_full_pipeline
    results["stage1"] = self.train_stage(
                        ^^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/training/trainer.py", line 234, in train_stage
    trainer.train(remaining_epochs, checkpoint_freq=checkpoint_freq if checkpoint_freq > 0 else None)
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py", line 474, in train
    self._update(batch)
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py", line 1015, in _update
    params, opt_state, train_loss, curr_grad, per_target_losses = self._update_fn(
                                                                  ^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/learn/max_likelihood.py", line 172, in update_fn
    params = device_put(params, replicate)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/api.py", line 2291, in device_put
    out_flat = dispatch.device_put_p.bind(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 518, in _batched_device_put_impl
    y = _device_put_impl(x, device=device, src=src, copy=cp)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 507, in _device_put_impl
    return _device_put_sharding_impl(x, aval, device, copy)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 438, in _device_put_sharding_impl
    multihost_utils.assert_equal(
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/experimental/multihost_utils.py", line 158, in assert_equal
    expected = broadcast_one_to_all(in_tree)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/experimental/multihost_utils.py", line 66, in broadcast_one_to_all
    jax.devices()).reshape(jax.process_count(), jax.local_device_count())
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: cannot reshape array of size 17 into shape (5,1)
srun: error: jwb0612: task 1: Exited with exit code 1
srun: error: jwb0615: task 2: Exited with exit code 1
srun: error: jwb0617: task 3: Exited with exit code 1
srun: error: jwb0629: task 4: Exited with exit code 1
srun: error: jwb0611: task 0: Exited with exit code 1
  Total time: 54.604924696s
  Throughput: 123.61 samples/s
  Done with 17 devices

------------------------------------------------------------
Testing with 18 device(s)...
------------------------------------------------------------
  Nodes needed:     5
  Device pattern:   split:4x4+2
  Running training...
2026-02-02 16:31:16.433401: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
2026-02-02 16:31:16.436470: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
2026-02-02 16:31:16.448556: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 2/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 2: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 2/5] JAX distributed initialized
[Rank 2] Local GPUs: 4, Total GPUs: 18
[Rank 2] Local devices: [CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11)]
[Rank 2] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 1/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 1: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 1/5] JAX distributed initialized
[Rank 1] Local GPUs: 4, Total GPUs: 18
[Rank 1] Local devices: [CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
[Rank 1] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
2026-02-02 16:31:16.454649: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 3/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 3: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 3/5] JAX distributed initialized
[Rank 3] Local GPUs: 4, Total GPUs: 18
[Rank 3] Local devices: [CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15)]
[Rank 3] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 0/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 0: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 0/5] JAX distributed initialized
[Rank 0] Local GPUs: 4, Total GPUs: 18
[Rank 0] Local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]
[Rank 0] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[Model] Using Allegro size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 288 does not divide the number of observations 2250. Trainer will skip 234 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 234 does not divide the number of observations 250. Trainer will skip 16 samples for state validation
  warnings.warn(
[Scaling] Node 4/5: local_device_ids = [0, 1]
[Scaling] Node 4: CUDA_VISIBLE_DEVICES = 0,1
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 4/5] JAX distributed initialized
[Rank 4] Local GPUs: 2, Total GPUs: 18
[Rank 4] Local devices: [CudaDevice(id=16), CudaDevice(id=17)]
[Rank 4] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17)]
============================================================
SCALING TEST
============================================================
Devices: 18
Distributed: True
Rank: 4/5
Local devices: 2
Global devices: 18
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 380, in <module>
    main()
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 360, in main
    results = trainer.train_full_pipeline()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/training/trainer.py", line 618, in train_full_pipeline
    results["stage1"] = self.train_stage(
                        ^^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/training/trainer.py", line 234, in train_stage
    trainer.train(remaining_epochs, checkpoint_freq=checkpoint_freq if checkpoint_freq > 0 else None)
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py", line 474, in train
    self._update(batch)
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py", line 1015, in _update
    params, opt_state, train_loss, curr_grad, per_target_losses = self._update_fn(
                                                                  ^^^^^^^^^^^^^^^^
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/learn/max_likelihood.py", line 172, in update_fn
    params = device_put(params, replicate)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/api.py", line 2291, in device_put
    out_flat = dispatch.device_put_p.bind(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 518, in _batched_device_put_impl
    y = _device_put_impl(x, device=device, src=src, copy=cp)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 507, in _device_put_impl
    return _device_put_sharding_impl(x, aval, device, copy)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 438, in _device_put_sharding_impl
    multihost_utils.assert_equal(
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/experimental/multihost_utils.py", line 158, in assert_equal
    expected = broadcast_one_to_all(in_tree)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/experimental/multihost_utils.py", line 66, in broadcast_one_to_all
    jax.devices()).reshape(jax.process_count(), jax.local_device_count())
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: cannot reshape array of size 18 into shape (5,2)
srun: error: jwb0629: task 4: Exited with exit code 1
srun: error: jwb0615: task 2: Exited with exit code 1
srun: error: jwb0612: task 1: Exited with exit code 1
srun: error: jwb0617: task 3: Exited with exit code 1
srun: error: jwb0611: task 0: Exited with exit code 1
  Total time: 33.852071536s
  Throughput: 199.39 samples/s
  Done with 18 devices

------------------------------------------------------------
Testing with 19 device(s)...
------------------------------------------------------------
  Nodes needed:     5
  Device pattern:   split:4x4+3
  Running training...
2026-02-02 16:31:59.217027: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 3/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 3: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 3/5] JAX distributed initialized
[Rank 3] Local GPUs: 4, Total GPUs: 19
[Rank 3] Local devices: [CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15)]
[Rank 3] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:32:00.094382: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 2/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 2: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 2/5] JAX distributed initialized
[Rank 2] Local GPUs: 4, Total GPUs: 19
[Rank 2] Local devices: [CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11)]
[Rank 2] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
2026-02-02 16:32:00.147953: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 1/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 1: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 1/5] JAX distributed initialized
[Rank 1] Local GPUs: 4, Total GPUs: 19
[Rank 1] Local devices: [CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
[Rank 1] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:32:00.665855: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 4/5: local_device_ids = [0, 1, 2]
[Scaling] Node 4: CUDA_VISIBLE_DEVICES = 0,1,2
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 4/5] JAX distributed initialized
[Rank 4] Local GPUs: 3, Total GPUs: 19
[Rank 4] Local devices: [CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
[Rank 4] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:32:03.841734: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 0/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 0: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 0/5] JAX distributed initialized
[Rank 0] Local GPUs: 4, Total GPUs: 19
[Rank 0] Local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]
[Rank 0] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: error: jwb0629: task 4: Exited with exit code 1
srun: error: jwb0612: task 1: Exited with exit code 1
srun: error: jwb0615: task 2: Exited with exit code 1
srun: error: jwb0617: task 3: Exited with exit code 1
srun: error: jwb0611: task 0: Exited with exit code 1
  Total time: 20.416079571s
  Throughput: 330.62 samples/s
  Done with 19 devices

------------------------------------------------------------
Testing with 20 device(s)...
------------------------------------------------------------
  Nodes needed:     5
  Device pattern:   uniform:4
  Running training...
[Model] Using Allegro size: default
[Model] Using Allegro size: default
[Model] Using Allegro size: default
[Model] Using Allegro size: default
[Model] Using Allegro size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Detected 18 unique species
[Model] Using Allegro config size: default
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
[Model] Mode: Prior + Allegro
[Model] Prior weights: {'bond': 0.5, 'angle': 0.25, 'dihedral': 0.25, 'repulsive': 1.0}
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 320 does not divide the number of observations 2250. Trainer will skip 10 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 240 does not divide the number of observations 250. Trainer will skip 10 samples for state validation
  warnings.warn(
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 320 does not divide the number of observations 2250. Trainer will skip 10 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 240 does not divide the number of observations 250. Trainer will skip 10 samples for state validation
  warnings.warn(
[Training] Initialized model with seed=193749
[Training] Applied NumpyDataLoader patch
[Training] 
============================================================
[Training] Training Stage: ADABELIEF (3 epochs, starting from 0)
[Training] ============================================================
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 320 does not divide the number of observations 2250. Trainer will skip 10 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 240 does not divide the number of observations 250. Trainer will skip 10 samples for state validation
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 320 does not divide the number of observations 2250. Trainer will skip 10 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 240 does not divide the number of observations 250. Trainer will skip 10 samples for state validation
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 320 does not divide the number of observations 2250. Trainer will skip 10 samples for state training
  warnings.warn(
/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/trainers/base.py:957: UserWarning: Batch size 240 does not divide the number of observations 250. Trainer will skip 10 samples for state validation
  warnings.warn(
[Scaling] Node 2/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 2: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 2/5] JAX distributed initialized
[Rank 2] Local GPUs: 4, Total GPUs: 20
[Rank 2] Local devices: [CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11)]
[Rank 2] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
============================================================
SCALING TEST
============================================================
Devices: 20
Distributed: True
Rank: 2/5
Local devices: 4
Global devices: 20
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
[Scaling] Node 4/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 4: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 4/5] JAX distributed initialized
[Rank 4] Local GPUs: 4, Total GPUs: 20
[Rank 4] Local devices: [CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
[Rank 4] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
============================================================
SCALING TEST
============================================================
Devices: 20
Distributed: True
Rank: 4/5
Local devices: 4
Global devices: 20
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
[Scaling] Node 1/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 1: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 1/5] JAX distributed initialized
[Rank 1] Local GPUs: 4, Total GPUs: 20
[Rank 1] Local devices: [CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
[Rank 1] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
============================================================
SCALING TEST
============================================================
Devices: 20
Distributed: True
Rank: 1/5
Local devices: 4
Global devices: 20
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
[Scaling] Node 0/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 0: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 0/5] JAX distributed initialized
[Rank 0] Local GPUs: 4, Total GPUs: 20
[Rank 0] Local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]
[Rank 0] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
============================================================
SCALING TEST
============================================================
Devices: 20
Distributed: True
Rank: 0/5
Local devices: 4
Global devices: 20
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
[Scaling] Node 3/5: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 3: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0611.juwels:29539
[Scaling] Actual processes: 5
[Rank 3/5] JAX distributed initialized
[Rank 3] Local GPUs: 4, Total GPUs: 20
[Rank 3] Local devices: [CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15)]
[Rank 3] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7), CudaDevice(id=8), CudaDevice(id=9), CudaDevice(id=10), CudaDevice(id=11), CudaDevice(id=12), CudaDevice(id=13), CudaDevice(id=14), CudaDevice(id=15), CudaDevice(id=16), CudaDevice(id=17), CudaDevice(id=18), CudaDevice(id=19)]
============================================================
SCALING TEST
============================================================
Devices: 20
Distributed: True
Rank: 3/5
Local devices: 4
Global devices: 20
============================================================
Capping edges and triplets. Beware of overflow, which is currently not being detected.
Estimated max. 900 edges.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
Use a custom scatter implementation
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
Out irreps 256x0e
Irreps after layer are Irreps()

============================================================
TRAINING WITH TIMING
============================================================
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use two atom species for oxygen and hydroge.
[Allegro] Use default mask
[Allegro] Use default mask
[Allegro] Use default mask
[Allegro] Use default mask
[Allegro] Use default mask
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Use a custom scatter implementation
Use a custom scatter implementation
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Out irreps 300x0e+556x1o+256x1e+556x2e+384x2o+512x3o+256x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Irreps after layer are 128x1o+128x1e+128x2e+128x2o+128x3o+128x3e
Use a custom scatter implementation
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Use a custom scatter implementation
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Out irreps 256x0e+768x1o+896x2e
Out irreps 256x0e+768x1o+896x2e
Out irreps 256x0e+768x1o+896x2e
Out irreps 256x0e+768x1o+896x2e
Out irreps 256x0e+768x1o+896x2e
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Irreps after layer are 128x1o+128x2e
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Out irreps 256x0e
Irreps after layer are 128x1o+128x2e
Irreps after layer are 128x1o+128x2e
Irreps after layer are 128x1o+128x2e
Out irreps 256x0e
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Use a custom scatter implementation
Use a custom scatter implementation
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/ops/scatter.py:92: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Irreps after layer are Irreps()
Out irreps 256x0e
Out irreps 256x0e
Out irreps 256x0e
Irreps after layer are Irreps()
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
Irreps after layer are Irreps()
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
Irreps after layer are Irreps()
Irreps after layer are Irreps()
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:183: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return asarray(x, dtype=self.dtype)
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/reductions.py:213: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in sum is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.
  return _reduction(a, "sum", np.sum, lax.add, 0, preproc=_cast_to_numeric,
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Force] Found precomputed forces.
[Epoch 0]:
	Average train loss: 363.29410
	Average val loss: 117.10234832763672
	Gradient norm: 2825.310302734375
	Elapsed time = 1.308 min
	Per-target losses:
		F | train loss: 363.2941000802176 | val loss: 117.10234832763672
[Epoch 0]:
	Average train loss: 363.29410
	Average val loss: 117.10234832763672
	Gradient norm: 2825.310302734375
	Elapsed time = 1.278 min
	Per-target losses:
		F | train loss: 363.2941000802176 | val loss: 117.10234832763672
[Epoch 0]:
	Average train loss: 363.29410
	Average val loss: 117.10234832763672
	Gradient norm: 2825.310302734375
	Elapsed time = 1.275 min
	Per-target losses:
		F | train loss: 363.2941000802176 | val loss: 117.10234832763672
[Epoch 0]:
	Average train loss: 363.29410
	Average val loss: 117.10234832763672
	Gradient norm: 2825.310302734375
	Elapsed time = 1.282 min
	Per-target losses:
		F | train loss: 363.2941000802176 | val loss: 117.10234832763672
[Epoch 0]:
	Average train loss: 363.29410
	Average val loss: 117.10234832763672
	Gradient norm: 2825.310302734375
	Elapsed time = 1.269 min
	Per-target losses:
		F | train loss: 363.2941000802176 | val loss: 117.10234832763672





[Epoch 1]:
	Average train loss: 98.61585
	Average val loss: 92.81465911865234
	Gradient norm: 163.88021850585938
	Elapsed time = 0.216 min
	Per-target losses:
		F | train loss: 98.61584908621651 | val loss: 92.81465911865234
[Epoch 1]:
	Average train loss: 98.61585
	Average val loss: 92.81465911865234
	Gradient norm: 163.88021850585938
	Elapsed time = 0.217 min
	Per-target losses:
		F | train loss: 98.61584908621651 | val loss: 92.81465911865234
[Epoch 1]:
	Average train loss: 98.61585
	Average val loss: 92.81465911865234
	Gradient norm: 163.88021850585938
	Elapsed time = 0.216 min
	Per-target losses:
		F | train loss: 98.61584908621651 | val loss: 92.81465911865234

[Epoch 1]:
	Average train loss: 98.61585
	Average val loss: 92.81465911865234
	Gradient norm: 163.88021850585938
	Elapsed time = 0.216 min
	Per-target losses:
		F | train loss: 98.61584908621651 | val loss: 92.81465911865234
[Epoch 1]:
	Average train loss: 98.61585
	Average val loss: 92.81465911865234
	Gradient norm: 163.88021850585938
	Elapsed time = 0.216 min
	Per-target losses:
		F | train loss: 98.61584908621651 | val loss: 92.81465911865234




[Epoch 2]:
	Average train loss: 90.25172
	Average val loss: 90.46514129638672
	Gradient norm: 17.359363555908203
	Elapsed time = 0.210 min
	Per-target losses:
		F | train loss: 90.25171879359654 | val loss: 90.46514129638672
[Epoch 2]:
	Average train loss: 90.25172
	Average val loss: 90.46514129638672
	Gradient norm: 17.359363555908203
	Elapsed time = 0.209 min
	Per-target losses:
		F | train loss: 90.25171879359654 | val loss: 90.46514129638672
[Epoch 2]:
	Average train loss: 90.25172
	Average val loss: 90.46514129638672
	Gradient norm: 17.359363555908203
	Elapsed time = 0.210 min
	Per-target losses:
		F | train loss: 90.25171879359654 | val loss: 90.46514129638672
[Epoch 2]:
	Average train loss: 90.25172
	Average val loss: 90.46514129638672
	Gradient norm: 17.359363555908203
	Elapsed time = 0.209 min
	Per-target losses:
		F | train loss: 90.25171879359654 | val loss: 90.46514129638672
[Epoch 2]:
	Average train loss: 90.25172
	Average val loss: 90.46514129638672
	Gradient norm: 17.359363555908203
	Elapsed time = 0.209 min
	Per-target losses:
		F | train loss: 90.25171879359654 | val loss: 90.46514129638672





[Training] 
Stage complete: train_loss=90.251719, val_loss=90.465141

Total training time: 124.32s

============================================================
SCALING TEST COMPLETE
============================================================
[Training] 
Stage complete: train_loss=90.251719, val_loss=90.465141

Total training time: 125.12s

============================================================
SCALING TEST COMPLETE
============================================================
[Training] 
Stage complete: train_loss=90.251719, val_loss=90.465141

Total training time: 124.66s

============================================================
SCALING TEST COMPLETE
============================================================
[Training] 
Stage complete: train_loss=90.251719, val_loss=90.465141
[Training] 
Stage complete: train_loss=90.251719, val_loss=90.465141

Total training time: 127.05s

============================================================
SCALING TEST COMPLETE
============================================================

Total training time: 125.31s
Timing data saved to: /p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scaling_results/run_20260202_150203/timing_20dev_13191139_20dev.json

============================================================
SCALING TEST COMPLETE
============================================================
  Total time: 162.531191634s
  Throughput: 41.53 samples/s
  Done with 20 devices

============================================================
Scaling test complete for devices 17-20
Results saved to: /p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scaling_results/run_20260202_150203/timing_job_13191139.csv
============================================================
