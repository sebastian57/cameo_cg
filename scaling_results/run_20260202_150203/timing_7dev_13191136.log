2026-02-02 16:32:05.979602: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 0/2: local_device_ids = [0, 1, 2, 3]
[Scaling] Node 0: CUDA_VISIBLE_DEVICES = 0,1,2,3
[Scaling] Coordinator: jwb0874.juwels:29536
[Scaling] Actual processes: 2
[Rank 0/2] JAX distributed initialized
[Rank 0] Local GPUs: 4, Total GPUs: 7
[Rank 0] Local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]
[Rank 0] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
2026-02-02 16:32:07.070420: E external/xla/xla/status_macros.cc:56] INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
*** Begin stack trace ***
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	PyObject_Vectorcall
	
	PyObject_Vectorcall
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyObject_Vectorcall
	
	
	
	
	
	
	PyObject_Vectorcall
	
	
	
	
	
	
	
	_PyObject_FastCallDictTstate
	_PyObject_Call_Prepend
	
	_PyObject_MakeTpCall
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	
	
	
	PyObject_CallMethodObjArgs
	PyImport_ImportModuleLevelObject
	
	PyEval_EvalCode
	
	
	
	_PyRun_SimpleFileObject
	_PyRun_AnyFileObject
	Py_RunMain
	Py_BytesMain
	
	__libc_start_main
	_start
*** End stack trace ***

[Scaling] Node 1/2: local_device_ids = [0, 1, 2]
[Scaling] Node 1: CUDA_VISIBLE_DEVICES = 0,1,2
[Scaling] Coordinator: jwb0874.juwels:29536
[Scaling] Actual processes: 2
[Rank 1/2] JAX distributed initialized
[Rank 1] Local GPUs: 3, Total GPUs: 7
[Rank 1] Local devices: [CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6)]
[Rank 1] All devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6)]
Traceback (most recent call last):
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/clean_code_base/scripts/train_scaling.py", line 193, in <module>
    from chemtrain.data.data_loaders import DataLoaders
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/chemtrain/__init__.py", line 16, in <module>
    import jax_md_mod
  File "/p/project1/cameo/schmidt36/chemtrain-deploy/external/chemtrain/jax_md_mod/__init__.py", line 55, in <module>
    import jax_md.partition
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/__init__.py", line 27, in <module>
    from jax_md import rigid_body
  File "/p/project1/cameo/schmidt36/clean_booster_env/lib/python3.12/site-packages/jax_md/rigid_body.py", line 1009, in <module>
    monomer = point_union_shape(onp.array([[0.0, 0.0]], f32), f32(1.0))
                                                              ^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 183, in __call__
    return asarray(x, dtype=self.dtype)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5191, in asarray
    return array(a, dtype=dtype, copy=bool(copy), order=order, device=device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py", line 5025, in array
    out_array: Array = lax_internal._convert_element_type(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 585, in _convert_element_type
    return convert_element_type_p.bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/lax/lax.py", line 2865, in _convert_element_type_bind
    operand = core.Primitive.bind(convert_element_type_p, operand,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 438, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 442, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/core.py", line 948, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/p/software/default/stages/2025/software/jax/0.4.34-gpsfbf-2024a-CUDA-12/lib/python3.12/site-packages/jax/_src/dispatch.py", line 90, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/pjrt/pjrt_stream_executor_client.cc:3497) device_count() % addressable_device_count() == 0 Each process is expected to have the same number of devices
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: error: jwb0885: task 1: Exited with exit code 1
srun: error: jwb0874: task 0: Exited with exit code 1
